\section{Lossy Compression}

\TG{You should say here that you will use lossy compression and in particular
LTC in the future.}

\subsection{LTC}
\label{sec:ltc}
\TG{expand acronym}
\TG{Add reference to LTC paper. Exlain that you are providing a more formal 
description here.}
The LTC algorithm approximates the data stream by a piece-wise linear function of time, with
an error bounded by parameter $\epsilon$. \english{We give the notation of LTC in the
following:} The algorithm receives a stream of data points $x_i$ at times $t_i$
($i \in \mathbb{N}$), and it transmits a stream of data points $\xi_i$ at times
$\tau_i$ ($i \in \mathbb{N}$). To simplify the notations, we assume that:
\begin{equation*}
\forall k \in \mathbb{N}, \  \exists ! i \in \mathbb{N} \  \tau_k = t_i
\end{equation*}
That is, transmission times coincide with reception times.
We define the \emph{shifted received points} \TG{I don't know why \textbackslash emph underlines
the text but it's not nice.} as follows:
\begin{equation*}
\forall k \in \mathbb{N}\ , \forall j \in \mathbb{N^*},\ (u^k_j, y^k_j) = (t_{i+j}, x_{i+j}), 
\end{equation*}
where $i$ is such that $t_i = \tau_k$ and:
\begin{equation*}
\forall k \in \mathbb{N},\  (u^k_0, y^k_0) = (\tau_k, \xi_k).
\end{equation*}
This definition is such that $y^k_j$ is the $j^{th}$ data point received
after the $k^{th}$ transmission and $u^k_j$ is the corresponding timestamp.
Figure~\ref{fig:ltc} illustrates the notations and algorithm. \TG{You should make sure 
that the figure isn't 2 pages below it's mention.}

The LTC algorithm maintains two lines, the \emph{high line}, and the \emph{low
line} defined by (1) the latest transmitted point and (2) the \emph{high point}
(high line) and the \emph{low point} (low line). When a point ($t_i$, $x_i$) is
received, the high line is updated as follows: if $x_i+\epsilon$ is below the
high line then the high line is updated to the line defined by the last
transmitted point and ($t_i$, $x_i+\epsilon$); otherwise, the high line is not
updated. Likewise, the low line is updated from $x_i-\epsilon$. Therefore, any
line located between the high line and the low line approximates the data points
received since the last transmitted point with an error bounded by $\epsilon$.

\begin{algorithm}
\begin{algorithmic}[1]
\Input
   \Desc{$(u^k_j, y^k_j)$}{$\quad \quad $Received data stream}
   \Desc{$\epsilon$}{$\quad \quad$Error bound}
\EndInput
\Output
   \Desc{tr}{Transmitted points}
\EndOutput
\State tr = $(u^0_0, y^0_0)$ \Comment{Last transmitted point}
\State k = 0 ; j = 1
\State (lp, hp) = ($y^0_1 - \epsilon$, $y^0_1 + \epsilon$) \Comment{Low and high points}

\While{True} \Comment{Process received points as they come}
    \State j += 1
    \State new\_lp = max($y^k_j-\epsilon$, line($u^k_j$, tr, ($u^k_{j-1}$, lp)))
    \State new\_hp = min($y^k_j+\epsilon$, line($u^k_j$, tr, ($u^k_{j-1}$, hp)))
    \If{new\_lp $\leq$ new\_hp} \Comment{Keep compressing}
        \State (lp, hp) = (new\_lp, new\_hp)
    \Else
        \State tr = $(u^k_{j-1}, (lp+hp)/2)$
        \Comment{Transmit point}
        \State k += 1
        \State j = 1
        \State (lp, hp) = ($y^k_j-\epsilon$, $y^k_j+\epsilon$)
    \EndIf
\EndWhile
\end{algorithmic}
\caption{Original LTC algorithm, adapted from~\cite{schoellhammer2004lightweight}.}
\label{algo:ltc}
\end{algorithm}

Using these notations, the original LTC algorithm can
be written as in Algorithm~\ref{algo:ltc}. For readability, we assume
that access to data points is blocking, i.e., the program will wait
until the points are available. We also assume that the content of
variable \texttt{tr} is transmitted after each assignment of this
variable. Function \texttt{line}, omitted for brevity, returns the
ordinate at abscissa $x$ (1st argument) of the line defined by the points
in its 2nd and 3rd arguments.

\begin{figure}[b]
\centering
\includegraphics[width=0.8\columnwidth]{./figures/ltc.pdf}
\caption{Illustration of the LTC algorithm. Blue 
dots are received points, red dots are transmitted points. Dashed lines 
represent the high and low lines when a point is 
transmitted.\vspace*{-0.3cm}}
\label{fig:ltc}
\end{figure}

\subsection{PLAMLis and Enhanced PLAMLis}
\TG{Expand acronyms. You should also add a list of acronyms to the document}
Similar to LTC, PLAMLis~\cite{liu2007energy} and Enhanced
PLAMLis~\cite{pham2008enhance} represent the original stream through a sequence of
line segments. The main idea of these two algorithms is to represent the stream
data over a time window using a minimum number of segments\english{(reduce transmission)}.
PLAMLis gives a greedy algorithm solution. Assume the input stream data points
$X=\{x_1, ..., x_W\}$ are received over a time
window of size $W$~\cite{liu2007energy, zordan2014performance} \TG{Reference looks misplaced}.
 Firstly, for each data
points $x_i$, $i \in \{1, ..., W\}$, a \TG{the longest segment? or a long segent?} 
longest segment $S_{i}$ whose end points
are $x_i$ and $x_j$ ($j>i$) is built. Thereby for the data points in the window, a
sequence of longest segments $S = {S_1, ..., S_W}$ is obtained. Secondly, to pick
the minimum number of subsets of S for representing original stream $X$, a
greedy algorithm is used to select the segment $S_k$ ($k \in \llbracket1,
W\rrbracket$) which covers the largest number of data points $x_i$ in $X$ at each
time, then remove it from $S$ and add it into a \texttt{result sequence} until
all data points in $X$ are covered. The result sequence is the result of
compression~\cite{zordan2012compress, zordan2014performance}.

Enhanced PLAMLis solves this problem with a top-down recursive segmentation
algorithm which has smaller computational cost than
PLAMLis~\cite{pham2008enhance, zordan2014performance}. Assume $W$ data points
$x_i$ in time window, the segment $S_{(1, W)}$ with end points $x_1$ and
$x_W$ is created, then checking whether the maximum error is within error
tolerance $\epsilon$ determines stopping the recursive or not. If the maximum
error is bigger than $\epsilon$, the segment is split into two shorter segments
$S_{(1, k)}$ and $S_{(k, W)}$ in data point $x_k$, $1<k<W$. Applying this
procedure recursively on each segment until the maximum error of all segments is
within the error tolerance~\cite{pham2008enhance, zordan2014performance}.

\TG{How do these algorithms compare to LTC?}

\subsection{Polynomial Regression}

Different from piece-wise linear approximations, Polynomial
Regression~\cite{zordan2014performance} gives a higher order $p \geqslant1$
approximation by using standard regression methods based on least squares
fitting~\cite{phillips2003interpolation} \TG{Undefined reference. Make sure that
Latex compilation doesn't say ``There were undefined references''.}. The approximation is a sequence
of curves (order = $p$) rather than linear segments. The algorithm starts with
collecting $p+1$ samples $\{x_1, ..., x_{p+1} \}$ to obtain the coefficients of
first $p$-order polynomial function. Upon receiving one sample $x_{p+1+i}$ at
each time, where $x_{p+1+i}$ indicates the $(p+1+i)_{th}$ sample ($i>0$) in this
approximation cycle, the best-fitting polynomial coefficients are re-computed
with $\{ x_1, ..., x_{p+1+i}\}$ and the algorithm checks whether the new polynomial approximates
the data points within the desired error tolerance. If not, the coefficients
of the previous regression are transmitted and a new approximation starts at the
current sample~\cite{zordan2014performance}. Assume $M_j^k$ is the $j^{th}$
polynomial regression model in the $k$ approximated procedure \TG{What is the $k$
approximated procedure?}, the steps of the
algorithm are given in Algorithm~\ref{algo:polynomial}. The least squares
fitting \english{cost significant computational complexity then piece-wise linear
approximations}, but polynomial regression gives better performance on
approximated accuracy~\cite{zordan2014performance} \TG{What does this mean? We can 
set $\epsilon$ in both cases.}.

\TG{So you need to keep in memory all the points between two transmissions?}

\begin{algorithm}
\begin{algorithmic}[1]
\Input
    \Desc{$\chi$}{Received data stream}
    \Desc{$\epsilon$}{Error bound}
    \Desc{$p$}{The order of polynomial function}
\EndInput
\Output
    \Desc{tr}{Transmitted coefficients}
\EndOutput

\State $S$ = $\O$
\State $k$=1; $j$=0
\While{True}
    \State $S = S \cup \chi$
    \If{$i \geqslant p+1$}
        \State j += 1
        \State $M_j^k$ = model($S$, $p$)    \Comment{Compute coefficients}
        \ForAll{$x_i \in S$ and $\hat{x}_i \in$ predict($M_j^k$)}   \Comment{Check if error bound is met}
            \If{$|\hat{x}_i - x_i| > \epsilon$}
                \State tr = $M_{j-1}^k$ \Comment{Transmit coefficients}
                \State k += 1; j = 0
                \State $S$ = $\chi$
            \EndIf
        \EndFor
    \EndIf
\EndWhile
\end{algorithmic}
\caption{Polynomial Regression Algorithm}
\label{algo:polynomial}
\end{algorithm}



\subsection{Adaptive ARMA}

Adaptive ARMA(A-ARMA)~\cite{lu2010optimized} is a improved version of ARMA
\TG{You should explain ARMA first} to
adapt ARMA to sensor nodes. Similar to the ARMA model, A-ARMA is also composed of
two terms, \texttt{Auto-Regression(AR)} term and \texttt{Moving-Average(MA)}
term, respectively predicting data value using $p$($q$) prior values or errors.
To deal with the limit of computational complexity, A-ARMA adopts low-order ARMA
with sliding window model~\cite{lu2010optimized}. The main idea of A-ARMA is
maintaining and updating a ARMA model in memory based on sliding window. Assume
we define a sliding window $W$ of size $W$, the minimum error tolerance on
root-mean-square error (RMSE) $th_{err}$ and \english{length of window movement each time
$S$}. The algorithm of A-ARMA is given in Algorithm~\ref{algo:A-ARMA}. The first
$W$ data points are used to initialize the ARMA model, and to compare the RMSE between the
original and predicted subsequent $S$ data by moving sliding window $S$ length
each time. If the RMSE is larger than $th_{err}$, the saved ARMA model is
remodeled with the current samples in sliding window~\cite{lu2010optimized}. In the
decompression process, the stream data are predicted based on the parameters
transmitted.

\TG{Again, explain if you wrote the algorithms or reused them.}

\begin{algorithm}
\begin{algorithmic}[1]
\Input
    \Desc{$stream$}{$\quad \quad \quad $Data stream received}
    \Desc{$W$}{$\quad \quad \quad $Sliding window}
    \Desc{$th_{err}$}{$\quad \quad $Threshold of error tolerance on root-mean-square error}
    \Desc{$S$}{$\quad \quad \quad $Length of sliding window move}
    \Desc{$p$}{$\quad \quad \quad $Order of AR term}
    \Desc{$q$}{$\quad \quad \quad $Order of MA term}
\EndInput
\Output
    \Desc{$model_{(p, q)}$}{$\quad \quad \quad $Parameters of ARMA($p$, $q$) model}
\EndOutput

\State Read stream till $W$ is full \Comment{Get first $W$ data from $stream$}
\State $model_{(p, q)}$ = build\_ARMA($W$.samples, $p$, $q$)  \Comment{Build ARMA model}
\While{$stream$ is not empty}
    \State $W$.go\_forward($S$) \Comment{Moving sliding window forward $S$ length}
    \State $samples$ = $W$.tail($S$)    
    \State $RMSE$ = compute\_error($samples$,  $model_{(p, q)}$.predict())
    \If{$RMSE > th_{err}$}
        \State $model_{(p, q)}$ = build\_ARMA($W$.samples, $p$, $q$)
        \State \Return $model_{(p, q)}$ 
    \Else
        \State \Return null \Comment{No transmitted data, model does not change}
    \EndIf
\EndWhile
\end{algorithmic}
\caption{A-ARMA algorithm}
\label{algo:A-ARMA}
\end{algorithm}

\subsection{Modified Adaptive Auto-Regression}

Modified Adaptive Auto-Regression (MA-AR) is a modified version of A-ARMA,
proposed by Zordan et al.~\cite{zordan2012compress}. In the A-ARMA algorithm, the
ARMA model is rebuilt over \TG{each?} sliding window, which might cause bad
performance, especially in highly noisy environments~\cite{zordan2012compress}.
The MA-AR algorithm uses a $p$-order AR model for each prediction cycle \TG{define prediction cycle} instead of
sliding window, and applies \TG{controls the?} absolute error on each data rather than RMSE of $S$
continuous data. Assume $M^{(n, i)}$ indicates the AR model built according to
data $\{x_n, ..., x_{n+p-1+i} \}$, where $i>0$, and $\hat{x}_{n+p-1+i}$
indicates the predicted data, then for each predicted \TG{prediction?} cycle, MA-AR works as
follows:

\begin{enumerate}
    \item Collect first $p$ samples in sensor node and send them to client side.
    \item Collect one sample $x_{n+p-1+i}$ \english{each time}, $i > 0$, to build
    $p$-order
    AR model $M^{(n, i)}$.
    \item Predict $x_{n+p-1+j}$ where $j \in \{1, ..., i\}$ using $M^{(n, i)}$.
    \item Check whether error $ |\hat{x}_{n+p-1+j} - x_{n+p-1+j}|$ is larger
    than error tolerance $\epsilon$.
        \begin{itemize}
            \item If $|\hat{x}_{n+p-1+j} - x_{n+p-1+j}| \leqslant \epsilon$, the
            model is kept. Repeat from step 2.
            \item Else the last model $M^{(n, i-1)}$ is encoded and transmitted,
            and new predict cycle is started from $x_{n+p-1+i}$.
        \end{itemize} 
\end{enumerate}
The main idea of this algorithm is continuous estimation of the AR parameters.
AR model is redefined only according to last coming sample, so the computational
cost is minimized and the parameters of model can be computed through least
squares minimization~\cite{zordan2012compress}. 
