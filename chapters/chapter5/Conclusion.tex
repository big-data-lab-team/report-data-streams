\chapter{Conclusion}

\todo{explain what has been implemented by Motsai On Neblina, in Conclusion
chapter}


\section{Summary}


IoT has been widely popularized in recent years and generates a huge amount of
streaming data. However, the limitations from hardware make some challenges e.g.
connected devices lacks of enough memory to store all the streaming data,
micro-controller in high performance to process method which has high
computational complexity, and the battery-based devices cannot have long
lifetime without recharge or change battery. Energy consumption is an urgent
problem in IoT, especially in the network consists of battery-powered devices,
the battery is depleted quickly because of massive computing and data
transmission.

In this thesis, we aim to decrease the rate of data transmitted by using data
stream summarization such that reducing the energy consumption of data
transmission thereby extending the lifetime of connected devices. 

Data compression is one of the techniques in data summarization, representing
original data by a compact version and keeping all information (lossless
compression) or retaining the information in certain accuracy. We introduce a
few general compression method in this thesis and we finally select Lightweight
Temporal Compression (LTC) algorithm for our experiments. LTC is a lossy
compression method and predicts data by a piece-wise linear function of time,
but it guarantees the construct accuracy in $\epsilon$ ($\epsilon$ is the error
bound we assigned). 

We desire to compress the acceleration data generated by Motsai's Neblina model,
but the original LTC only was proposed for 1D streaming data while the connected
objects are often produced multi-dimensional streams, e.g. acceleration data and
gyroscopic data.

Thus, We re-describe the original LTC and extend LTC to dimension $n$. Moreover,
LTC n-dimension can work in different norm, but its compression result and costs
are depending on the norm used. In the experiments, we collect 2 biceps curl
data-set which have different size, and a comparison of compression ratio,
memory usage and processing time between infinity norm and euclidean norm is
presented with using these data-set.  

Then we implement the LTC n-dimension algorithm into Neblina to measure the
compression ratio of LTC n-dimension algorithm and energy consumption
(compression and transmission) when human is walking or running. From the
result, through using LTC n-dimension algorithm, Neblina can at least save 10\%
energy when the error bound $\epsilon$ is 48.8g. Additionally, in order to test
the compression result of LTC n-dimension, we compare the LTC n-dimension
algorithm with polynomial regression compression algorithm in different
dimension, and we found that LTC n-dimension outperforms polynomial regression
method in terms of compression ratio, regardless of the dimension or degree of
regression.


% 然而固件上的局限性，使得我们无法完成一些操作，比如，保存全部的数据因为内存空间，运行复杂的算法因为CPU计算能力，长时间的工作 电池的容量，
% 电力消耗是很重要的问题在IoT中，尤其是电池设备，他们的电池会持续的消耗殆尽 去进行大量计算和传输无限的数据。 在这个论文里，我们主要研究 使用summarization 去减少 传输的数据量从而减少电力消耗。数据压缩which summarization的一种，可以帮助我们把元数据转化为压缩版本，并且保留 全部(lossless)/或一定精度(lossy)的数据信息。 在THesis 中，我们给出了一些常用的压缩算法，并从中，我们选择使用LTC压缩算法which lossy compression but make sure the reconstruct accuracy with $\epsilon$ 进行实验。

% 在实验中，我们使用LTC 压缩Neblina所产生的acceleroter 数据，来自Human activies. 但是original LTC 只是用来压缩 一位数据，然而，很多数据都是n维的 比如说。。。，
% 所以在这篇Thesis里 我们 重新定义了LTC，并把LTC 拓展到了N维， 并且给出了他的表达时。N-维的LTC 可与被使用在 n-dimension 和 任意的norm
% 不同的norm或造成不同的结果，我们在论文里给出了 当n dimension LTC 被使用在 euclidean norm 和 infinity norm 时候的结果，给出了 压缩 crul时候的 压缩率。 并把LTC-N implement， 并测试使用它进行 walk 和 running 时候的compression ratio，并与 auto regression 压缩 进行对比

% 我在18年的9月到12月 到Motsai 进行了实习，把LTC n infinity norm and euclidian norm 算法嵌入到了 Neblina 里。并且研究结果发布了论文在。。。。。。。。






% In this thesis, we extend LTC compression algorithm to $n$ dimensions and give its formulation. This extension method is norm-independent and can work with the data stream have $n$ attributes. 
%   \item Formalize the description of original LTC algorithm
%   \item Extend LTC to dimension $n$.
%   \item Propose an algebraic formulation of n-dimensional LTC algorithm.
%   \item Introduce an norm-independent expression of n-dimensional LTC, according
%   to the algebraic formulation.
% we extend LTC to n dimension, and 
% formalizes the description initially proposed
% in~\cite{schoellhammer2004lightweight} and presents our norm-independent
% extension to dimension $n$, together with description of our implementation in

% extension to n dimension and give his performance in different norm Euclidean and Manhattan  infinity norm
% give implement and test the result through Neblina, compare the compression ratio with different dimension and different norm
% and compare the energy saving

% Compare with the Polynomial regression with has best compression ratio in ~\cite{zordan2014performance}.

% how every we did measure the energy consumption, just give compression ratio




\section{Limitation}

In LTC with n-dimension the main limitation is the memory usage, in Euclidean norm, with can be considered as the intersection of n-ball.
It is difficult to compute this. we found that the theory .......
How every it takes ... time complexity
We provide a method .... which give $O(n\times (\log{n})^D)$

It is also too complexity and spend time to short interval communication.(the last data point has not been process completely yet when new data coming)
according to the result in Chapter 4, the method we provide can work for the transmission rate in 200Hz, but if the the interval increase, it might require more memory.

% 我们希望选择一个 方法 不会依赖数据的重复性， 如果在模写情况下，这个数据成一定 固定的模式
% 那么 其他model可能会提供更多的compression ratio
% 比如说 LEC S-LEC 字典型压缩算法  会对那些  出现重复几率大，或者重复模式时候 提供更好的效果。

\section{Future work}

尝试 其他算法， 是否可以提高 energy saving， 尝试寻找 更小复杂度 时间空间都是 解决n-ball 的intersection problem
sometimes, we wanna lossless data, so a frame work which can support a efficent lossless algorithem and lossy algorithm is need. 
从 s-lec 来看, it could give good compression ratio than other lossless method.
try to find a method which can support multi-dimension or extend it into n-dimension

check the Slides of before meeting 
