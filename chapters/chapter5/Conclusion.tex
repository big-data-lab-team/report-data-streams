\chapter{Conclusion}


\section{Summary}


IoT has been widely popularized in recent years and generates a huge amount of
streaming data. However, the limitations from hardware make some challenges, for
instance, connected devices lacks of enough memory to store all the streaming
data, the micro-controller has trouble with methods which has high computational
complexity, and the battery-based devices cannot have long lifetime without
recharging or changing battery. Energy consumption is an urgent problem in IoT,
especially in the battery-powered devices, large amount of computing and
transmission will drain the battery quickly.

In this thesis, we plan to find a summarization method which can be fitted in
connected objects and can process multi-dimensional streams to reduce the number
of data transmitted. In that case, we can save the energy during transmission,
thereby extending the work time of devices.

Data compression is one of the techniques in data summarization, representing
original data by a compact version and keeping all information (lossless
compression) or retaining the information in certain accuracy. We introduce a
few general compression method in this thesis and we finally select Lightweight
Temporal Compression (LTC) algorithm for our experiments. LTC is a lossy
compression method and predicts data by a piece-wise linear function of time,
but it guarantees the reconstruct accuracy in $\epsilon$ ($\epsilon$ is the
error bound we assigned). 

We plan to compress the three-dimensional acceleration data generated by
Motsai's Neblina model, but the original LTC only was proposed for 1D streaming
data. Thus, we give a definite form to describe the original LTC and extend LTC
to dimension $n$. Moreover, LTC n-dimension can work in different norm, but its
compression result and costs depend on the norm used. In the experiments, we
collect 2 biceps curl data-set which have different size, and a comparison of
compression ratio, memory usage and processing time between infinity norm and
Euclidean norm is presented with using these data-set.

Then we implement the LTC n-dimension algorithm into Neblina to measure the
compression ratio of LTC n-dimension algorithm and energy consumption
(compression and transmission) when human is walking or running. From the
result, through using LTC n-dimension algorithm, Neblina can at least save 10\%
energy when the error bound $\epsilon$ is 48.8g. Additionally, in order to test
the compression result of LTC n-dimension, we compare the LTC with n-dimension
algorithm with polynomial regression compression algorithm in different
dimension, and we found that LTC n-dimension for Infinity norm outperforms
polynomial regression method in terms of compression ratio, regardless of the
dimension or degree of regression \TG{??how is it possible? See comments in
Ch4.}. The LTC n-dimension has been deployed in Motsai's Neblina during my 4
months internship from September to December 2018, it can be selected the
dimension $n$ and the norm (Infinity norm or Euclidean norm).

\section{Limitation}


The main limitation of LTC n-dimension algorithm is the memory usage. In
Euclidean norm, LTC n-dimension can be considered as the intersection of
n-balls, but it is difficult to check if there is a intersection among n-balls.
The Helly's theorem is the best algorithm we could find, however this algorithm
is too complex to use in the connected objects which have limited resource.  We
provide a method which utilizes plane sweep and bisection to determine if a set
of n-balls have a public intersection.

This method provided leads a $O(n\times (\log{2\epsilon})^{d-1})$ complexity,
where $n$ is the number of data points we seen so far, $\epsilon$ is the error
tolerance and $d$ is the dimension of the stream, but it requires a lot of
memory space and processing time. 

From the Section~\ref{sec:experiment2-ltc}, the tolerable latency at 200Hz is
5-ms, the process of current data point must be finished before receiving new
data point. We have to make sure the maximum latency is smaller than tolerable
latency. Thus, the LTC n-dimension cannot work in high transmission rate, such
as 400Hz or 800Hz. In addition, in order to reduce the memory usage of LTC with
n-dimension for Euclidean norm, we limit the length of the set of n-balls $S$,
but it might reduce the compression ratio. Thus, a better algorithm is needed to
deal with the memory usage and processing time of the intersection check in
Euclidean norm.


\section{Future work}

In the next step, we would like to  find algorithms which have lower time and
space complexity to handle the intersection check. We will review other
compression algorithms, attempting to achieve more energy saving.  Moreover,
lossless algorithm is necessary sometimes, typically in e-health application. So
a framework which can support both efficient lossless and lossy algorithm and
can work with multi-dimension stream is also one of the research
direction in our future work.
