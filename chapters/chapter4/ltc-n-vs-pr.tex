\section{LTC n-dimension compare with Regression}

From the previous experiments, we know that LTC has good performance on 
walking and running accelerometer data sets. However as we seen, the running data set (Figure~\ref{fig:datasets-2}) looks like it is made of many high-degree plane curves.
We wonder whether high-degree Regression compression method performs better with our accelerometer data sets. In this
paragraph, we implement the Polynomial Regression compression method mentioned in~\ref{sec:polynomial} with LTC in different dimensions. \TG{\#\#refer to description in ch2}

% need  a graph for polynomial regression with different p,  by using 200Hz
% walking and running data set, also need a table to show the RMSE and
% compression ratio, Max error.

\subsection{Implementation of Polynomial Regression}

We implemented polynomial regression method to compress 3D acceleration data
($t$, $a.x$, $a.y$, $a.z$). In the implementation, we process polynomial regression
compression method on each accelerometer parameter, with the relationship between independent variables $t$ (Time-stamp) and dependent
variables $a.x$, $a.y$ or $a.z$ (e.g. $t \sim a.x$). It means 
three regression models shell be transmitted to represent a curve in 3D space.
For tolerance checking, we use infinity norm
and Euclidean norm. 
\todo{explain Polynomial regression clearly, and add a pseudo-code}
\BO{Do I need a pseudo-code to show what this algorithm looks like?}

\BO{Do I need to add a chapter about extension regression method to nD?}

\TG{\#\#You didn't explain in Ch2 how polynomial regression was extended to dim n.}


We use Polynomial Regression method on previous walking and running data set.
Figure~\ref{fig:poly-regression-3-degree} and Figure~\ref{fig:poly-regression-5-degree} shows the reconstructed data. \TG{\#\#Wrong reference, there isn't
a Figure 8d.}


\todo{add this sentence to conclusion}
The implementation needs much memory to record data points,
and some CPU time to compute coefficients.


\begin{figure*}
\centering
\begin{subfigure}{\columnwidth}
\centering
\includegraphics[width=0.3\columnwidth]{figures/regression-p3-in-x.pdf}
\includegraphics[width=0.3\columnwidth]{figures/regression-p3-in-y.pdf}
\includegraphics[width=0.3\columnwidth]{figures/regression-p3-in-z.pdf}
\caption{Regression degree=3 with Infinity norm}
\end{subfigure}

\centering
\begin{subfigure}{\columnwidth}
\centering
\includegraphics[width=0.3\columnwidth]{figures/regression-p3-Eu-x.pdf}
\includegraphics[width=0.3\columnwidth]{figures/regression-p3-Eu-y.pdf}
\includegraphics[width=0.3\columnwidth]{figures/regression-p3-Eu-z.pdf}
\caption{Regression degree=3 with Euclidean norm}
\end{subfigure}

\caption{Reconstructed data by using 5-degree Regression compression method}
\label{fig:poly-regression-3-degree}
\end{figure*}

%-------------------------------------------------------%

\begin{figure*}
\centering
\begin{subfigure}{\columnwidth}
\centering
\includegraphics[width=0.3\columnwidth]{figures/regression-p5-in-x.pdf}
\includegraphics[width=0.3\columnwidth]{figures/regression-p5-in-y.pdf}
\includegraphics[width=0.3\columnwidth]{figures/regression-p5-in-z.pdf}
\caption{Regression degree=5 with Infinity norm}
\end{subfigure}

\centering
\begin{subfigure}{\columnwidth}
\centering
\includegraphics[width=0.3\columnwidth]{figures/regression-p5-Eu-x.pdf}
\includegraphics[width=0.3\columnwidth]{figures/regression-p5-Eu-y.pdf}
\includegraphics[width=0.3\columnwidth]{figures/regression-p5-Eu-z.pdf}
\caption{Regression degree=5 with Euclidean norm}
\end{subfigure}

\caption{Reconstructed data by using 5-degree Regression compression method}
\label{fig:poly-regression-5-degree}
\end{figure*}

\subsection{Results of Comparison}
In our implementation, for a regression model which has N-degree and
M-parameters we need M*(N+1) coefficients and extra time-stamp used to record
where should the model stop. In the Table , It obvious that LTC n-dimension work
better than Polynomial regression, because it need more bytes to save the
coefficients. In our case, coefficients are recorded as float points which would
use 4 bytes per each. The total number of bytes needed to represent original
data is (N+1)*M*4+4 (Int32 for Time-stamp). Polynomial regression using more
processing time to calculate coefficients and build model when each new data
point comes. 

From the Table~\ref{table:CR-compare-walking} and Table ~\ref{table:CR-compare-running}, We can learn that increasing the Dimension $n$ is detrimental to compression ratio with both n-dimensional LTC and Polynomial Regression, and LTC gives better compression ratio then regression method on different dimensions. Also same with experiment 2 in Section~\ref{sec:experiment2-ltc}, the Compression ratio is higher for the infinity norm than for the Euclidean and is higher for the walking than for running.
For given degree of polynomial regression method, the higher degree results smaller compression ratio for walking and running in general, but the variations are slight. However, in Table~\ref{table:CR-compare-walking}, when dimension is 2 and 3, the 5-degree regression regression compresses more data then 3-degree regression method by using Infinity norm to check error tolerance in walking data set, and in Table~\ref{table:CR-compare-running} the 5-degree regression method works better when dimension equals 1 for both norm, equals 2 for infinity norm.



\begin{table}[]
\begin{tabular}{|l|l|l|l|l|l|l|l|}
\hline
           & \multicolumn{2}{c|}{LTC} & \multicolumn{2}{c|}{Regression degree = 3} & \multicolumn{3}{l|}{Regression degree = 5}\\ \hline
Dimension & Infinity   & Euclidean   & Infinity    & Euclidean     & Infinity      & \multicolumn{2}{l|}{Euclidean} \\ \hline
1          & 90.1\%     & 90.1\%      & 89\%        & 89\%          & 88.96\%       & \multicolumn{2}{l|}{88.96\%}   \\ \hline
2          & 89.6\%     & 88.7\%      & 83.35\%     & 83.35\%       & 83.55\%       & \multicolumn{2}{l|}{83.1\%}    \\ \hline
3          & 88.9\%     & 87.6\%      & 80.24\%     & 78.68\%       & 80.8\%        & \multicolumn{2}{l|}{77.96\%}   \\ \hline
\end{tabular}
\caption{Comparisons of compression ratio on Walking data set\TG{\#\#What are the \% here? Compression ratio?} \TG{\#\#This table and the next one are not referenced or discussed in the text!}}
\label{table:CR-compare-walking}
\end{table}


\begin{table}[]
\begin{tabular}{|l|l|l|l|l|l|l|l|}
\hline
           & \multicolumn{2}{c|}{LTC} & \multicolumn{2}{c|}{Regression degree = 3} & \multicolumn{3}{l|}{Regression degree = 5}          \\ \hline
Dimension & Infinity   & Euclidean   & Infinity            & Euclidean           & Infinity& \multicolumn{2}{l|}{Euclidean} \\ \hline
1          & 74.7\%     & 74.7\%      & 70.7\%      & 70.7\%        & 71.1\%        & \multicolumn{2}{l|}{71.1\%}    \\ \hline
2          & 70.6\%     & 68.6\%      & 58.3\%      & 57.4\%        & 58.4\%        & \multicolumn{2}{l|}{57.35\%}   \\ \hline
3          & 68.6\%     & 64.4\%      & 51.1\%      & 48\%          & 50.2\%        & \multicolumn{2}{l|}{47.92\%}   \\ \hline
\end{tabular}
\caption{Comparisons of compression ratio on Running data set}
\label{table:CR-compare-running}
\end{table}
